{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическое задание к уроку 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  when father is dysfunctional and is so selfish...   \n",
       "1  thanks for lyft credit cannot use cause they d...   \n",
       "2                                bihday your majesty   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [when, father, is, dysfunctional, and, is, so,...   \n",
       "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                            [bihday, your, majesty]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                  [bihday, majesty]   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                  [bihday, majesty]   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  [father, dysfunctional, selfish, drags, kids, ...  \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...  \n",
       "2                                  [bihday, majesty]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_pickle('tweet_tokens')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_1(list_str):\n",
    "    text=' '.join([ch for ch in list_str])\n",
    "    return text.strip()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['father dysfunctional selfish drags kids dysfunction run',\n",
       "       'thanks lyft credit use cause offer wheelchair vans pdx disapointed getthanked',\n",
       "       'bihday majesty', ...,\n",
       "       'hillary campaigned today ohio omg used words like assets liability never clinton say thee word radicalization',\n",
       "       'happy work conference right mindset leads culture development organizations work mindset',\n",
       "       'song glad free download shoegaze newmusic newsong'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_stemmed_documents=data['tweet_stemmed'].apply(lambda x: def_1(x)).values\n",
    "tweet_lemmatized_documents=data['tweet_lemmatized'].apply(lambda x: def_1(x)).values\n",
    "tweet_stemmed_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Создайте мешок слов с помощью sklearn.feature_extraction.text.CountVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    "●\tИгнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    "●\tОграничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    "●\tИсключим стоп-слова с помощью stop_words='english'.\n",
    "●\tОтобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью CountVectorizer.get_feature_names().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>adapt environment</th>\n",
       "      <th>adventure</th>\n",
       "      <th>affirmation</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yoyou</th>\n",
       "      <th>yoyou time</th>\n",
       "      <th>yoyou yoyou</th>\n",
       "      <th>yoyour</th>\n",
       "      <th>yoyoyou</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolutely  account  act  actor  actually  adapt  adapt environment  \\\n",
       "0     0           0        0    0      0         0      0                  0   \n",
       "1     0           0        0    0      0         0      0                  0   \n",
       "2     0           0        0    0      0         0      0                  0   \n",
       "\n",
       "   adventure  affirmation  ...  york  young  youtube  yoyou  yoyou time  \\\n",
       "0          0            0  ...     0      0        0      0           0   \n",
       "1          0            0  ...     0      0        0      0           0   \n",
       "2          0            0  ...     0      0        0      0           0   \n",
       "\n",
       "   yoyou yoyou  yoyour  yoyoyou  yr  yummy  \n",
       "0            0       0        0   0      0  \n",
       "1            0       0        0   0      0  \n",
       "2            0       0        0   0      0  \n",
       "\n",
       "[3 rows x 1000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(ngram_range=(1, 2), analyzer='word', binary=False,\n",
    "                                   max_df=0.9,max_features=1000,stop_words='english')\n",
    "\n",
    "bag_of_words_tweet_stemmed = count_vectorizer.fit_transform(tweet_stemmed_documents)\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "pd.DataFrame(bag_of_words_tweet_stemmed.toarray(), columns = feature_names).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>adapt environment</th>\n",
       "      <th>adventure</th>\n",
       "      <th>affirmation</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yoyou</th>\n",
       "      <th>yoyou time</th>\n",
       "      <th>yoyou yoyou</th>\n",
       "      <th>yoyour</th>\n",
       "      <th>yoyoyou</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolutely  account  act  actor  actually  adapt  adapt environment  \\\n",
       "0     0           0        0    0      0         0      0                  0   \n",
       "1     0           0        0    0      0         0      0                  0   \n",
       "2     0           0        0    0      0         0      0                  0   \n",
       "\n",
       "   adventure  affirmation  ...  york  young  youtube  yoyou  yoyou time  \\\n",
       "0          0            0  ...     0      0        0      0           0   \n",
       "1          0            0  ...     0      0        0      0           0   \n",
       "2          0            0  ...     0      0        0      0           0   \n",
       "\n",
       "   yoyou yoyou  yoyour  yoyoyou  yr  yummy  \n",
       "0            0       0        0   0      0  \n",
       "1            0       0        0   0      0  \n",
       "2            0       0        0   0      0  \n",
       "\n",
       "[3 rows x 1000 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(ngram_range=(1, 2), analyzer='word', binary=False,\n",
    "                                   max_df=0.9,max_features=1000,stop_words='english')\n",
    "\n",
    "bag_of_words_tweet_lemmatized = count_vectorizer.fit_transform(tweet_lemmatized_documents)\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "pd.DataFrame(bag_of_words_tweet_lemmatized.toarray(), columns = feature_names).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Создайте мешок слов с помощью sklearn.feature_extraction.text.TfidfVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    "●\tИгнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    "●\tОграничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    "●\tИсключим стоп-слова с помощью stop_words='english'.\n",
    "●\tОтобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью TfidfVectorizer.get_feature_names().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>adapt environment</th>\n",
       "      <th>adventure</th>\n",
       "      <th>affirmation</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yoyou</th>\n",
       "      <th>yoyou time</th>\n",
       "      <th>yoyou yoyou</th>\n",
       "      <th>yoyour</th>\n",
       "      <th>yoyoyou</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolutely  account  act  actor  actually  adapt  adapt environment  \\\n",
       "0   0.0         0.0      0.0  0.0    0.0       0.0    0.0                0.0   \n",
       "1   0.0         0.0      0.0  0.0    0.0       0.0    0.0                0.0   \n",
       "2   0.0         0.0      0.0  0.0    0.0       0.0    0.0                0.0   \n",
       "\n",
       "   adventure  affirmation  ...  york  young  youtube  yoyou  yoyou time  \\\n",
       "0        0.0          0.0  ...   0.0    0.0      0.0    0.0         0.0   \n",
       "1        0.0          0.0  ...   0.0    0.0      0.0    0.0         0.0   \n",
       "2        0.0          0.0  ...   0.0    0.0      0.0    0.0         0.0   \n",
       "\n",
       "   yoyou yoyou  yoyour  yoyoyou   yr  yummy  \n",
       "0          0.0     0.0      0.0  0.0    0.0  \n",
       "1          0.0     0.0      0.0  0.0    0.0  \n",
       "2          0.0     0.0      0.0  0.0    0.0  \n",
       "\n",
       "[3 rows x 1000 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfid_vectorizer =TfidfVectorizer(ngram_range=(1, 2), analyzer='word', binary=False,\n",
    "                                   max_df=0.9,max_features=1000,stop_words='english')\n",
    "\n",
    "bag_of_words_tweet_stemmed = tfid_vectorizer.fit_transform(tweet_stemmed_documents)\n",
    "feature_names = tfid_vectorizer.get_feature_names()\n",
    "pd.DataFrame(bag_of_words_tweet_stemmed.toarray(), columns = feature_names).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>adapt environment</th>\n",
       "      <th>adventure</th>\n",
       "      <th>affirmation</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yoyou</th>\n",
       "      <th>yoyou time</th>\n",
       "      <th>yoyou yoyou</th>\n",
       "      <th>yoyour</th>\n",
       "      <th>yoyoyou</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolutely  account  act  actor  actually  adapt  adapt environment  \\\n",
       "0   0.0         0.0      0.0  0.0    0.0       0.0    0.0                0.0   \n",
       "1   0.0         0.0      0.0  0.0    0.0       0.0    0.0                0.0   \n",
       "2   0.0         0.0      0.0  0.0    0.0       0.0    0.0                0.0   \n",
       "\n",
       "   adventure  affirmation  ...  york  young  youtube  yoyou  yoyou time  \\\n",
       "0        0.0          0.0  ...   0.0    0.0      0.0    0.0         0.0   \n",
       "1        0.0          0.0  ...   0.0    0.0      0.0    0.0         0.0   \n",
       "2        0.0          0.0  ...   0.0    0.0      0.0    0.0         0.0   \n",
       "\n",
       "   yoyou yoyou  yoyour  yoyoyou   yr  yummy  \n",
       "0          0.0     0.0      0.0  0.0    0.0  \n",
       "1          0.0     0.0      0.0  0.0    0.0  \n",
       "2          0.0     0.0      0.0  0.0    0.0  \n",
       "\n",
       "[3 rows x 1000 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfid_vectorizer =TfidfVectorizer(ngram_range=(1, 2), analyzer='word', binary=False,\n",
    "                                   max_df=0.9,max_features=1000,stop_words='english')\n",
    "\n",
    "bag_of_words_tweet_lemmatized = tfid_vectorizer.fit_transform(tweet_lemmatized_documents)\n",
    "feature_names = tfid_vectorizer.get_feature_names()\n",
    "pd.DataFrame(bag_of_words_tweet_lemmatized.toarray(), columns = feature_names).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Натренируем gensim.models.Word2Vec модель на наших данных.\n",
    "●\tТренировать будем на токенизированных твитах combine_df['tweet_token']\n",
    "●\tУстановим следующие параметры: size=200, window=5, min_count=2, sg = 1, hs = 0, negative = 10, workers= 32, seed = 34.\n",
    "●\tИспользуем функцию train() с параметром total_examples равным длине combine_df['tweet_token'], количество epochs установим 20.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.info()['models'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['when', 'father', 'is', 'dysfunctional', 'and', 'is', 'so', 'selfish', 'he', 'drags', 'his', 'kids', 'into', 'his', 'dysfunction', 'run']),\n",
       "       list(['thanks', 'for', 'lyft', 'credit', 'can', 'not', 'use', 'cause', 'they', 'do', 'not', 'offer', 'wheelchair', 'vans', 'in', 'pdx', 'disapointed', 'getthanked']),\n",
       "       list(['bihday', 'your', 'majesty']), ...,\n",
       "       list(['hillary', 'campaigned', 'today', 'in', 'ohio', 'omg', 'used', 'words', 'like', 'assets', 'liability', 'never', 'once', 'did', 'clinton', 'say', 'thee', 'word', 'radicalization']),\n",
       "       list(['happy', 'at', 'work', 'conference', 'right', 'mindset', 'leads', 'to', 'culture', 'of', 'development', 'organizations', 'work', 'mindset']),\n",
       "       list(['my', 'song', 'so', 'glad', 'free', 'download', 'shoegaze', 'newmusic', 'newsong'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tweet_token'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2Vec=gensim.models.Word2Vec(size=200, window=5, min_count=2, sg = 1, hs = 0, negative = 10, workers= 32, seed = 34)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['when', 'father', 'is', 'dysfunctional', 'and', 'is', 'so', 'selfish', 'he', 'drags', 'his', 'kids', 'into', 'his', 'dysfunction', 'run']),\n",
       "       list(['thanks', 'for', 'lyft', 'credit', 'can', 'not', 'use', 'cause', 'they', 'do', 'not', 'offer', 'wheelchair', 'vans', 'in', 'pdx', 'disapointed', 'getthanked']),\n",
       "       list(['bihday', 'your', 'majesty']), ...,\n",
       "       list(['hillary', 'campaigned', 'today', 'in', 'ohio', 'omg', 'used', 'words', 'like', 'assets', 'liability', 'never', 'once', 'did', 'clinton', 'say', 'thee', 'word', 'radicalization']),\n",
       "       list(['happy', 'at', 'work', 'conference', 'right', 'mindset', 'leads', 'to', 'culture', 'of', 'development', 'organizations', 'work', 'mindset']),\n",
       "       list(['my', 'song', 'so', 'glad', 'free', 'download', 'shoegaze', 'newmusic', 'newsong'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tweet_token'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2Vec.build_vocab(data['tweet_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9150339, 11711500)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2Vec.train(data['tweet_token'],total_examples=data['tweet_token'].shape[0],epochs=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Давайте немного потестируем нашу модель Word2Vec и посмотрим, как она работает. Мы зададим слово positive = \"dinner\", и модель вытащит из корпуса наиболее похожие слова c помощью функции most_similar. То же самое попробуем со словом \"trump\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dinner [('shawarma', 0.5739580392837524), ('cookout', 0.5720238089561462), ('spaghetti', 0.5658062696456909)]\n",
      "trump [('donald', 0.558621883392334), ('suppoer', 0.5223381519317627), ('unfit', 0.520941436290741)]\n"
     ]
    }
   ],
   "source": [
    "result = word2Vec.most_similar(positive=\"dinner\", topn=3)\n",
    "print('dinner',result)\n",
    "result = word2Vec.most_similar(positive=\"trump\", topn=3)\n",
    "print('trump',result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Из приведенных выше примеров мы видим, что наша модель word2vec хорошо справляется с поиском наиболее похожих слов для данного слова. Но как она это делает? Она изучила векторы для каждого уникального слова наших данных и использует косинусное сходство, чтобы найти наиболее похожие векторы (слова).\n",
    "Давайте проверим векторное представление любого слова из нашего корпуса, например \"food\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.16260464,  0.20376222,  0.43490514,  0.54155004,  0.08045436,\n",
       "        0.05884673, -0.91281575, -0.02477957, -0.37246084,  0.3404071 ,\n",
       "        0.21369961,  0.8979313 ,  0.23352347, -0.33705923, -0.3925573 ,\n",
       "        0.13241506, -0.3267432 , -0.08988018,  0.86172664,  0.04725142,\n",
       "       -0.28488982,  0.23925182,  0.19023663,  0.55599856,  0.17425345,\n",
       "       -0.4249877 ,  0.11920348, -0.48809528, -0.5754252 , -0.57919437,\n",
       "        0.4308769 , -0.01530803, -0.017687  , -0.4175602 ,  0.18305205,\n",
       "        0.2766019 ,  0.3189314 , -0.07469253,  0.36651638,  0.1270167 ,\n",
       "       -0.48204118,  0.9228072 ,  0.05431063, -0.08990847,  0.3289554 ,\n",
       "       -0.4214604 ,  0.01989678, -0.12990203,  0.5943816 ,  0.30524385,\n",
       "        0.524544  ,  0.26876083, -0.19708535, -0.04484678, -0.17148119,\n",
       "        0.54533905, -0.17409454, -0.29804608,  0.01743136,  0.10185908,\n",
       "        0.02862702, -0.09078954, -0.54069185, -0.67407924, -0.14552888,\n",
       "        0.85000956,  0.19587529, -0.69680285, -0.5335884 ,  0.55368096,\n",
       "        0.8825875 ,  0.44070256,  0.73567635, -0.23046842,  0.32020953,\n",
       "       -0.32955226, -0.0157431 , -0.22004157,  0.55171615,  0.31117344,\n",
       "        0.53980416, -0.6620761 , -0.41674158, -0.54055506,  0.14024362,\n",
       "       -0.02650135, -0.17467888,  0.57810533, -0.3839175 ,  0.43025988,\n",
       "        0.34387514, -0.5418981 ,  0.8496911 , -0.7993002 , -0.26053327,\n",
       "       -0.13194542,  0.30365843, -0.1247281 , -0.20163144, -0.32602605,\n",
       "        0.0451169 , -0.69637144,  0.29225168,  0.43559098,  0.6497063 ,\n",
       "       -0.16413862, -0.33545744, -0.3601335 ,  0.07814501,  0.32608843,\n",
       "       -0.7659584 , -0.30668128,  0.17400078,  0.00490158, -0.01055586,\n",
       "        0.24959846,  0.0698243 ,  0.15755475, -0.20762697, -0.79943335,\n",
       "       -0.16162515, -0.08012893,  0.97699296, -0.64005995, -0.7006522 ,\n",
       "        0.00240942, -0.29611006, -0.100735  , -0.2648028 , -0.54184586,\n",
       "       -0.542079  ,  0.1210088 ,  0.13952018, -0.08017732,  0.434094  ,\n",
       "        0.12666716,  0.5368371 , -0.4406108 ,  0.12102323,  0.35953766,\n",
       "       -0.6024451 , -0.45356548, -0.0527317 , -0.08785405, -0.5791487 ,\n",
       "        0.06426398,  0.6768934 , -0.3636429 , -0.2961611 , -0.69775265,\n",
       "       -0.18116008,  0.47449836,  0.01942198, -0.34735593, -0.28867358,\n",
       "       -0.08026138,  0.04980535, -0.07579297, -0.24907354,  0.37428278,\n",
       "       -0.29078034,  0.8267435 ,  1.1722066 ,  0.15193358,  0.2046013 ,\n",
       "        0.43526086,  0.1113487 , -0.5299453 , -0.14109698, -0.18452333,\n",
       "       -0.12461907, -0.091068  ,  0.59421504, -0.13695414, -0.25768182,\n",
       "        0.0980979 ,  0.09865868,  0.15910704,  0.6457935 ,  0.40877604,\n",
       "       -0.44783193, -0.25880763,  0.48248115,  0.00564448, -0.33281267,\n",
       "        0.0923616 , -0.32588893, -0.7370699 ,  0.07704116,  0.13411398,\n",
       "       -0.5374382 ,  0.72035575,  0.70969474,  0.56189996, -0.48101997,\n",
       "       -0.19262488, -0.43464315,  0.45639667, -0.15965308, -0.2640046 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2Vec['food']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2Vec['food'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Поскольку наши данные содержат твиты, а не только слова, нам придется придумать способ использовать векторы слов из модели word2vec для создания векторного представления всего твита. Существует простое решение этой проблемы, мы можем просто взять среднее значение всех векторов слов, присутствующих в твите. Длина результирующего вектора будет одинаковой, то есть 200. Мы повторим тот же процесс для всех твитов в наших данных и получим их векторы. Теперь у нас есть 200 функций word2vec для наших данных.\n",
    "Необходимо создать вектор для каждого твита, взяв среднее значение векторов слов, присутствующих в твите. В цикле сделать:  vec += model_w2v[word].reshape((1, size))\n",
    "и поделить финальный вектор на количество слов в твите.\n",
    "На выходе должен получиться wordvec_df.shape = (49159, 200).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49157, 200)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df=[]\n",
    "size=word2Vec.vector_size\n",
    "vec=0\n",
    "for tweet in data['tweet_token']:\n",
    "      if len(tweet):\n",
    "        for word in tweet:\n",
    "            if word2Vec.wv.vocab.get(word):\n",
    "                vec += word2Vec[word]\n",
    "                \n",
    "        wordvec_df.append(vec/len(tweet))    \n",
    "pd.DataFrame(wordvec_df).shape        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
