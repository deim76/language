{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическое задание к уроку 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.objectives import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.1.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.10.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание из 2-х частей.\n",
    "Берем отызывы за лето (из архива с материалами или предыдущего занятия)\n",
    "1. Учим conv сеть для классификации - выбить auc выше 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>В целом удобноное приложение...из минусов хотя...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Отлично все</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Стал зависать на 1% работы антивируса. Дальше ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Очень удобно, работает быстро.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date\n",
       "0       5                                     It just works!  2017-08-14\n",
       "1       4  В целом удобноное приложение...из минусов хотя...  2017-08-14\n",
       "2       5                                        Отлично все  2017-08-14\n",
       "3       5  Стал зависать на 1% работы антивируса. Дальше ...  2017-08-14\n",
       "4       5                     Очень удобно, работает быстро.  2017-08-14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_excel('отзывы за лето.xls')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=data.copy()\n",
    "#df_train, df_val=train_test_split(data, test_size=0.33, random_state=42)\n",
    "#df_train, df_val=train_test_split(train, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=data['Rating'].value_counts().shape[0]\n",
    "num_classes+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 200\n",
    "max_len = 40\n",
    "\n",
    "# Training\n",
    "epochs = 20\n",
    "batch_size =32\n",
    "print_batch_n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)\n",
    "\n",
    "df_train['Content'] = df_train['Content'].apply(preprocess_text)\n",
    "#df_val['Content'] = df_val['Content'].apply(preprocess_text)\n",
    "#df_test['Content'] = df_test['Content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = \" \".join(df_train[\"Content\"])\n",
    "train_corpus = train_corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Cats\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "tokens = word_tokenize(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "\n",
    "dist = FreqDist(tokens_filtered)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "    padding = [0]*(maxlen-len(result))\n",
    "    return padding + result[-maxlen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray([text_to_sequence(text, max_len) for text in df_train[\"Content\"]], dtype=np.int32)\n",
    "#x_test = np.asarray([text_to_sequence(text, max_len) for text in df_test[\"Content\"]], dtype=np.int32)\n",
    "#x_val = np.asarray([text_to_sequence(text, max_len) for text in df_val[\"Content\"]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train = keras.utils.to_categorical(df_train[\"Rating\"], num_classes)\n",
    "#y_val = keras.utils.to_categorical(df_val[\"Rating\"], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Conv1D(1024, 7))\n",
    "model.add(Activation(\"relu\"))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Conv1D(1024, 7))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "\n",
    "model.add(GlobalMaxPool1D())\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_64 (Embedding)     (None, 40, 128)           25600     \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 34, 1024)          918528    \n",
      "_________________________________________________________________\n",
      "activation_213 (Activation)  (None, 34, 1024)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 28, 1024)          7341056   \n",
      "_________________________________________________________________\n",
      "activation_214 (Activation)  (None, 28, 1024)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_61 (Glo (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 10)                10250     \n",
      "_________________________________________________________________\n",
      "activation_215 (Activation)  (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "activation_216 (Activation)  (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 8,295,500\n",
      "Trainable params: 8,295,500\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18593 samples, validate on 2066 samples\n",
      "Epoch 1/20\n",
      "18593/18593 [==============================] - 38s 2ms/step - loss: 0.2088 - accuracy: 0.9259 - val_loss: 0.2311 - val_accuracy: 0.9095\n",
      "Epoch 2/20\n",
      "18593/18593 [==============================] - 37s 2ms/step - loss: 0.1875 - accuracy: 0.9315 - val_loss: 0.2219 - val_accuracy: 0.9163\n",
      "Epoch 3/20\n",
      "18593/18593 [==============================] - 37s 2ms/step - loss: 0.1834 - accuracy: 0.9326 - val_loss: 0.2281 - val_accuracy: 0.9116\n",
      "Epoch 4/20\n",
      "18593/18593 [==============================] - 37s 2ms/step - loss: 0.1805 - accuracy: 0.9345 - val_loss: 0.2297 - val_accuracy: 0.9149\n",
      "Epoch 5/20\n",
      "18593/18593 [==============================] - 37s 2ms/step - loss: 0.1752 - accuracy: 0.9361 - val_loss: 0.2341 - val_accuracy: 0.9112\n",
      "Epoch 6/20\n",
      "18593/18593 [==============================] - 37s 2ms/step - loss: 0.1706 - accuracy: 0.9383 - val_loss: 0.2376 - val_accuracy: 0.9144\n",
      "Epoch 7/20\n",
      "18593/18593 [==============================] - 38s 2ms/step - loss: 0.1652 - accuracy: 0.9402 - val_loss: 0.2370 - val_accuracy: 0.9113\n",
      "Epoch 8/20\n",
      "18593/18593 [==============================] - 37s 2ms/step - loss: 0.1593 - accuracy: 0.9429 - val_loss: 0.2550 - val_accuracy: 0.9092\n",
      "Epoch 9/20\n",
      "18593/18593 [==============================] - 37s 2ms/step - loss: 0.1542 - accuracy: 0.9448 - val_loss: 0.2601 - val_accuracy: 0.9089\n",
      "Epoch 10/20\n",
      "18593/18593 [==============================] - 37s 2ms/step - loss: 0.1484 - accuracy: 0.9471 - val_loss: 0.2822 - val_accuracy: 0.9062\n",
      "Epoch 11/20\n",
      "18593/18593 [==============================] - 38s 2ms/step - loss: 0.1441 - accuracy: 0.9487 - val_loss: 0.2814 - val_accuracy: 0.9129\n",
      "Epoch 12/20\n",
      "18593/18593 [==============================] - 38s 2ms/step - loss: 0.1415 - accuracy: 0.9496 - val_loss: 0.2720 - val_accuracy: 0.9105\n",
      "Epoch 13/20\n",
      "18593/18593 [==============================] - 37s 2ms/step - loss: 0.1365 - accuracy: 0.9514 - val_loss: 0.2872 - val_accuracy: 0.9086\n",
      "Epoch 14/20\n",
      "18593/18593 [==============================] - 38s 2ms/step - loss: 0.1326 - accuracy: 0.9524 - val_loss: 0.3133 - val_accuracy: 0.9060\n",
      "Epoch 15/20\n",
      "18593/18593 [==============================] - 38s 2ms/step - loss: 0.1279 - accuracy: 0.9540 - val_loss: 0.3177 - val_accuracy: 0.9100\n",
      "Epoch 16/20\n",
      "18593/18593 [==============================] - 38s 2ms/step - loss: 0.1263 - accuracy: 0.9547 - val_loss: 0.3356 - val_accuracy: 0.9072\n",
      "Epoch 17/20\n",
      "18593/18593 [==============================] - 38s 2ms/step - loss: 0.1242 - accuracy: 0.9552 - val_loss: 0.3514 - val_accuracy: 0.9090\n",
      "Epoch 18/20\n",
      "18593/18593 [==============================] - 38s 2ms/step - loss: 0.1240 - accuracy: 0.9555 - val_loss: 0.3503 - val_accuracy: 0.9055\n",
      "Epoch 19/20\n",
      "18593/18593 [==============================] - 38s 2ms/step - loss: 0.1225 - accuracy: 0.9556 - val_loss: 0.3706 - val_accuracy: 0.9076\n",
      "Epoch 20/20\n",
      "18593/18593 [==============================] - 38s 2ms/step - loss: 0.1221 - accuracy: 0.9561 - val_loss: 0.3726 - val_accuracy: 0.9066y: 0.95\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 38s 2ms/step - loss: 0.1221 - accuracy: 0.9561  модель немного переучилась но accuracy: 0.9561"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Берём предобученный word2vec и его эмбедингами инициализируем сетку, как влияет на качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2Vec=gensim.models.Word2Vec(size=200, window=5, min_count=2, sg = 1, hs = 0, negative = 10, workers= 32, seed = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2Vec.build_vocab(df_train['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3570870, 17175380)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2Vec.train(df_train['Content'],total_examples=df_train['Content'].shape[0],epochs=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(word2Vec.wv.get_keras_embedding(train_embeddings=False))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Conv1D(128, 7))\n",
    "model.add(Activation(\"relu\"))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Conv1D(128, 7))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "\n",
    "model.add(GlobalMaxPool1D())\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18593 samples, validate on 2066 samples\n",
      "Epoch 1/20\n",
      "18593/18593 [==============================] - 8s 417us/step - loss: 0.2356 - accuracy: 0.9192 - val_loss: 0.2586 - val_accuracy: 0.9013\n",
      "Epoch 2/20\n",
      "18593/18593 [==============================] - 5s 277us/step - loss: 0.2078 - accuracy: 0.9254 - val_loss: 0.2592 - val_accuracy: 0.9008\n",
      "Epoch 3/20\n",
      "18593/18593 [==============================] - 5s 282us/step - loss: 0.2018 - accuracy: 0.9268 - val_loss: 0.2555 - val_accuracy: 0.9025\n",
      "Epoch 4/20\n",
      "18593/18593 [==============================] - 5s 281us/step - loss: 0.1993 - accuracy: 0.9269 - val_loss: 0.2505 - val_accuracy: 0.9034\n",
      "Epoch 5/20\n",
      "18593/18593 [==============================] - 5s 281us/step - loss: 0.1957 - accuracy: 0.9282 - val_loss: 0.2415 - val_accuracy: 0.9038\n",
      "Epoch 6/20\n",
      "18593/18593 [==============================] - 5s 279us/step - loss: 0.1928 - accuracy: 0.9288 - val_loss: 0.2365 - val_accuracy: 0.9055\n",
      "Epoch 7/20\n",
      "18593/18593 [==============================] - 5s 284us/step - loss: 0.1906 - accuracy: 0.9305 - val_loss: 0.2340 - val_accuracy: 0.9073\n",
      "Epoch 8/20\n",
      "18593/18593 [==============================] - 5s 277us/step - loss: 0.1877 - accuracy: 0.9319 - val_loss: 0.2374 - val_accuracy: 0.9076\n",
      "Epoch 9/20\n",
      "18593/18593 [==============================] - 5s 277us/step - loss: 0.1846 - accuracy: 0.9333 - val_loss: 0.2344 - val_accuracy: 0.9077\n",
      "Epoch 10/20\n",
      "18593/18593 [==============================] - 5s 279us/step - loss: 0.1811 - accuracy: 0.9344 - val_loss: 0.2435 - val_accuracy: 0.9071\n",
      "Epoch 11/20\n",
      "18593/18593 [==============================] - 5s 278us/step - loss: 0.1779 - accuracy: 0.9355 - val_loss: 0.2378 - val_accuracy: 0.9097\n",
      "Epoch 12/20\n",
      "18593/18593 [==============================] - 5s 284us/step - loss: 0.1757 - accuracy: 0.9362 - val_loss: 0.2457 - val_accuracy: 0.9095\n",
      "Epoch 13/20\n",
      "18593/18593 [==============================] - 5s 283us/step - loss: 0.1711 - accuracy: 0.9374 - val_loss: 0.2621 - val_accuracy: 0.9085\n",
      "Epoch 14/20\n",
      "18593/18593 [==============================] - 5s 293us/step - loss: 0.1691 - accuracy: 0.9387 - val_loss: 0.2564 - val_accuracy: 0.9105\n",
      "Epoch 15/20\n",
      "18593/18593 [==============================] - 5s 289us/step - loss: 0.1655 - accuracy: 0.9395 - val_loss: 0.2554 - val_accuracy: 0.9100\n",
      "Epoch 16/20\n",
      "18593/18593 [==============================] - 5s 284us/step - loss: 0.1628 - accuracy: 0.9407 - val_loss: 0.2749 - val_accuracy: 0.9071\n",
      "Epoch 17/20\n",
      "18593/18593 [==============================] - 5s 284us/step - loss: 0.1613 - accuracy: 0.9410 - val_loss: 0.2793 - val_accuracy: 0.9069\n",
      "Epoch 18/20\n",
      "18593/18593 [==============================] - 5s 284us/step - loss: 0.1582 - accuracy: 0.9423 - val_loss: 0.2788 - val_accuracy: 0.9067\n",
      "Epoch 19/20\n",
      "18593/18593 [==============================] - 5s 283us/step - loss: 0.1562 - accuracy: 0.9432 - val_loss: 0.2908 - val_accuracy: 0.9083\n",
      "Epoch 20/20\n",
      "18593/18593 [==============================] - 5s 282us/step - loss: 0.1540 - accuracy: 0.9438 - val_loss: 0.3043 - val_accuracy: 0.9051\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "предобученый эмбедингами позволяет сократить аохитектуру сети без особой потери качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
