{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическое задание к уроку 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D, SimpleRNN, LSTM, GRU, Masking\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.objectives import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping  \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.1.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.10.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Поэкспериментировать с моделью генерации текста, попробовать модель на словах, посмотреть что отработает лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = 'evgenyi_onegin.txt'\n",
    "path_to_file_1 = 'War_1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 286984 characters\n"
     ]
    }
   ],
   "source": [
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = open(path_to_file_1, 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text=text_1#[:586544]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Залог достойнее тебя,\n",
      "                        Достойнее души прекрасной,\n",
      "                        Святой исполненной мечты,\n",
      "                        Поэзии живой и ясной,\n",
      "                        Высоких дум и простоты;\n",
      "                        Но так и быть - рукой пристрастной\n",
      "                     \n"
     ]
    }
   ],
   "source": [
    "print(text[300:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab_char = sorted(set(text))\n",
    "print('{} unique characters'.format(len(vocab_char)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Cats\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "nltk.download(\"punkt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "  w = w.lower().strip()\n",
    "\n",
    "  # creating a space between a word and the punctuation following it\n",
    "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "  w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "  w = re.sub(r\"[^a-zA-Zа-яА-Я?.!,']+\", \" \", w)\n",
    "\n",
    "  w = w.strip()\n",
    "\n",
    "  # adding a start and an end token to the sentence\n",
    "  # so that the model know when to start and stop predicting.\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8501 unique characters\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(preprocess_sentence(text))\n",
    "vocab_word = sorted(set(tokens))\n",
    "print('{} unique characters'.format(len(vocab_word)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab_word)}\n",
    "idx2char = np.array(vocab_word)\n",
    "\n",
    "text_as_int_word = np.array([char2idx[c] for c in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum length sentence you want for a single input in characters\n",
    "seq_length = 6\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "word_dataset = tf.data.Dataset.from_tensor_slices(text_as_int_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for i in  word_dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 98,  4, ...,  3, 32,  4])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Александр Сергеевич Пушкин\n",
      "\n",
      "                                Евгений Онегин\n",
      "                                Роман в стихах\n",
      "\n",
      "                        Не мысля гордый свет забавить,\n",
      "                        Вниманье дружбы возлюбя,\n",
      "                        Хотел бы я тебе представить\n",
      "                        Залог достойнее тебя,\n",
      "                        Достойнее души прекрасной,\n",
      "                        Святой исполненной мечты,\n",
      "                        Поэзии живой и ясной,\n",
      "                        Высоких дум и простоты;\n",
      "                        Но так и быть - рукой пристрастной\n",
      "                        Прими собранье пестрых глав,\n",
      "                        Полусмешных, полупечальных,\n",
      "                        Простонародных, идеальных,\n",
      "                        Небрежный плод моих забав,\n",
      "                        Бессонниц, легких вдохновений,\n",
      "                        Незрелых и увядших лет,\n",
      "                        Ума холодных наблюдений\n",
      "                        И сердца горестных замет.\n",
      "\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'багряною'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int_word\n",
    "idx2char[229]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = word_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "   \n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([   3   98    4  184 6528 5923], shape=(6,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for i in  dataset.take(1):\n",
    "    print(i[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 6), (64, 6)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab_word)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 300\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "                                 \n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "         tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        \n",
    "                                   \n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size=len(vocab_word),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    period=20,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 64 steps\n",
      "Epoch 1/200\n",
      "64/64 [==============================] - 5s 78ms/step - loss: 7.3712\n",
      "Epoch 2/200\n",
      "64/64 [==============================] - 5s 76ms/step - loss: 7.3709\n",
      "Epoch 3/200\n",
      "64/64 [==============================] - 5s 78ms/step - loss: 7.3705\n",
      "Epoch 4/200\n",
      "64/64 [==============================] - 5s 79ms/step - loss: 7.3746\n",
      "Epoch 5/200\n",
      "64/64 [==============================] - 5s 79ms/step - loss: 7.3699\n",
      "Epoch 6/200\n",
      "64/64 [==============================] - 5s 77ms/step - loss: 7.3710\n",
      "Epoch 7/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3689\n",
      "Epoch 8/200\n",
      "64/64 [==============================] - 5s 76ms/step - loss: 7.3613\n",
      "Epoch 9/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3695\n",
      "Epoch 10/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3720\n",
      "Epoch 11/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3604\n",
      "Epoch 12/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3677\n",
      "Epoch 13/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3704\n",
      "Epoch 14/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3662\n",
      "Epoch 15/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3675\n",
      "Epoch 16/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3704\n",
      "Epoch 17/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3652\n",
      "Epoch 18/200\n",
      "64/64 [==============================] - 5s 77ms/step - loss: 7.3639\n",
      "Epoch 19/200\n",
      "64/64 [==============================] - 5s 77ms/step - loss: 7.3694\n",
      "Epoch 20/200\n",
      "64/64 [==============================] - 6s 94ms/step - loss: 7.3694\n",
      "Epoch 21/200\n",
      "64/64 [==============================] - 5s 77ms/step - loss: 7.3692\n",
      "Epoch 22/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3684\n",
      "Epoch 23/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3704\n",
      "Epoch 24/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3657\n",
      "Epoch 25/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3688\n",
      "Epoch 26/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3617\n",
      "Epoch 27/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3647\n",
      "Epoch 28/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3737\n",
      "Epoch 29/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3689\n",
      "Epoch 30/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3692\n",
      "Epoch 31/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3752\n",
      "Epoch 32/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3721\n",
      "Epoch 33/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3667\n",
      "Epoch 34/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3717\n",
      "Epoch 35/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3679\n",
      "Epoch 36/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3674\n",
      "Epoch 37/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3692\n",
      "Epoch 38/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3682\n",
      "Epoch 39/200\n",
      "64/64 [==============================] - 5s 76ms/step - loss: 7.3730\n",
      "Epoch 40/200\n",
      "64/64 [==============================] - 6s 92ms/step - loss: 7.3648\n",
      "Epoch 41/200\n",
      "64/64 [==============================] - 5s 76ms/step - loss: 7.3705\n",
      "Epoch 42/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3685\n",
      "Epoch 43/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3630\n",
      "Epoch 44/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3713\n",
      "Epoch 45/200\n",
      "64/64 [==============================] - 5s 73ms/step - loss: 7.3661\n",
      "Epoch 46/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3711\n",
      "Epoch 47/200\n",
      "64/64 [==============================] - 5s 73ms/step - loss: 7.3712\n",
      "Epoch 48/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3682\n",
      "Epoch 49/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3680\n",
      "Epoch 50/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3732\n",
      "Epoch 51/200\n",
      "64/64 [==============================] - 5s 78ms/step - loss: 7.3671\n",
      "Epoch 52/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3708\n",
      "Epoch 53/200\n",
      "64/64 [==============================] - 5s 73ms/step - loss: 7.3693\n",
      "Epoch 54/200\n",
      "64/64 [==============================] - 5s 72ms/step - loss: 7.3723\n",
      "Epoch 55/200\n",
      "64/64 [==============================] - 5s 73ms/step - loss: 7.3628\n",
      "Epoch 56/200\n",
      "64/64 [==============================] - 5s 73ms/step - loss: 7.3695\n",
      "Epoch 57/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3686\n",
      "Epoch 58/200\n",
      "64/64 [==============================] - 5s 76ms/step - loss: 7.3736\n",
      "Epoch 59/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3719\n",
      "Epoch 60/200\n",
      "64/64 [==============================] - 6s 93ms/step - loss: 7.3653\n",
      "Epoch 61/200\n",
      "64/64 [==============================] - 5s 78ms/step - loss: 7.3629\n",
      "Epoch 62/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3728\n",
      "Epoch 63/200\n",
      "64/64 [==============================] - 5s 73ms/step - loss: 7.3676\n",
      "Epoch 64/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3681\n",
      "Epoch 65/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3712\n",
      "Epoch 66/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3664\n",
      "Epoch 67/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3634\n",
      "Epoch 68/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3693\n",
      "Epoch 69/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3692\n",
      "Epoch 70/200\n",
      "64/64 [==============================] - 5s 73ms/step - loss: 7.3642\n",
      "Epoch 71/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3671\n",
      "Epoch 72/200\n",
      "64/64 [==============================] - 5s 73ms/step - loss: 7.3634\n",
      "Epoch 73/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3632\n",
      "Epoch 74/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3688\n",
      "Epoch 75/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3671\n",
      "Epoch 76/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3651\n",
      "Epoch 77/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3683\n",
      "Epoch 78/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3701\n",
      "Epoch 79/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3650\n",
      "Epoch 80/200\n",
      "64/64 [==============================] - 6s 91ms/step - loss: 7.3651\n",
      "Epoch 81/200\n",
      "64/64 [==============================] - 5s 77ms/step - loss: 7.3703\n",
      "Epoch 82/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3667\n",
      "Epoch 83/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3708\n",
      "Epoch 84/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3665\n",
      "Epoch 85/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3674\n",
      "Epoch 86/200\n",
      "64/64 [==============================] - 5s 79ms/step - loss: 7.3711\n",
      "Epoch 87/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3671\n",
      "Epoch 88/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3675\n",
      "Epoch 89/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3679\n",
      "Epoch 90/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3684\n",
      "Epoch 91/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3709\n",
      "Epoch 92/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3651\n",
      "Epoch 93/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3628\n",
      "Epoch 94/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3692\n",
      "Epoch 95/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3658\n",
      "Epoch 96/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3658\n",
      "Epoch 97/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3700\n",
      "Epoch 98/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3631\n",
      "Epoch 99/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3686\n",
      "Epoch 100/200\n",
      "64/64 [==============================] - 6s 91ms/step - loss: 7.3672\n",
      "Epoch 101/200\n",
      "64/64 [==============================] - 5s 77ms/step - loss: 7.3649\n",
      "Epoch 102/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3710\n",
      "Epoch 103/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3719\n",
      "Epoch 104/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3663\n",
      "Epoch 105/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3622\n",
      "Epoch 106/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3672\n",
      "Epoch 107/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3651\n",
      "Epoch 108/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3663\n",
      "Epoch 109/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3743\n",
      "Epoch 110/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3661\n",
      "Epoch 111/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3690\n",
      "Epoch 112/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3625\n",
      "Epoch 113/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3604\n",
      "Epoch 114/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3669\n",
      "Epoch 115/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3695\n",
      "Epoch 116/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3622\n",
      "Epoch 117/200\n",
      "64/64 [==============================] - 5s 76ms/step - loss: 7.3673\n",
      "Epoch 118/200\n",
      "64/64 [==============================] - 5s 73ms/step - loss: 7.3710\n",
      "Epoch 119/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3663\n",
      "Epoch 120/200\n",
      "64/64 [==============================] - 6s 91ms/step - loss: 7.3663\n",
      "Epoch 121/200\n",
      "64/64 [==============================] - 5s 78ms/step - loss: 7.3684\n",
      "Epoch 122/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3713\n",
      "Epoch 123/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3684\n",
      "Epoch 124/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3626\n",
      "Epoch 125/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3660\n",
      "Epoch 126/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3685\n",
      "Epoch 127/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3685\n",
      "Epoch 128/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3686\n",
      "Epoch 129/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3685\n",
      "Epoch 130/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3689\n",
      "Epoch 131/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3686\n",
      "Epoch 132/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3691\n",
      "Epoch 133/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3751\n",
      "Epoch 134/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3680\n",
      "Epoch 135/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3695\n",
      "Epoch 136/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3634\n",
      "Epoch 137/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3638\n",
      "Epoch 138/200\n",
      "64/64 [==============================] - 5s 76ms/step - loss: 7.3703\n",
      "Epoch 139/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3643\n",
      "Epoch 140/200\n",
      "64/64 [==============================] - 6s 92ms/step - loss: 7.3737\n",
      "Epoch 141/200\n",
      "64/64 [==============================] - 5s 77ms/step - loss: 7.3668\n",
      "Epoch 142/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3683\n",
      "Epoch 143/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3712\n",
      "Epoch 144/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3644\n",
      "Epoch 145/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3674\n",
      "Epoch 146/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3672\n",
      "Epoch 147/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3670\n",
      "Epoch 148/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3671\n",
      "Epoch 149/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3693\n",
      "Epoch 150/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3713\n",
      "Epoch 151/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3689\n",
      "Epoch 152/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3705\n",
      "Epoch 153/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3676\n",
      "Epoch 154/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3648\n",
      "Epoch 155/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3710\n",
      "Epoch 156/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3662\n",
      "Epoch 157/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3750\n",
      "Epoch 158/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3725\n",
      "Epoch 159/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3694\n",
      "Epoch 160/200\n",
      "64/64 [==============================] - 6s 93ms/step - loss: 7.3730\n",
      "Epoch 161/200\n",
      "64/64 [==============================] - 5s 78ms/step - loss: 7.3663\n",
      "Epoch 162/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3707\n",
      "Epoch 163/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3710\n",
      "Epoch 164/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3743\n",
      "Epoch 165/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3669\n",
      "Epoch 166/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3728\n",
      "Epoch 167/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3701\n",
      "Epoch 168/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3635\n",
      "Epoch 169/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3693\n",
      "Epoch 170/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3684\n",
      "Epoch 171/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3626\n",
      "Epoch 172/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3643\n",
      "Epoch 173/200\n",
      "64/64 [==============================] - 5s 78ms/step - loss: 7.3715\n",
      "Epoch 174/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3772\n",
      "Epoch 175/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3685\n",
      "Epoch 176/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3656\n",
      "Epoch 177/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3647\n",
      "Epoch 178/200\n",
      "64/64 [==============================] - 5s 76ms/step - loss: 7.3667\n",
      "Epoch 179/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3669\n",
      "Epoch 180/200\n",
      "64/64 [==============================] - 6s 91ms/step - loss: 7.3766\n",
      "Epoch 181/200\n",
      "64/64 [==============================] - 5s 78ms/step - loss: 7.3672\n",
      "Epoch 182/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3606\n",
      "Epoch 183/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3675\n",
      "Epoch 184/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3686\n",
      "Epoch 185/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3771\n",
      "Epoch 186/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3716\n",
      "Epoch 187/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3667\n",
      "Epoch 188/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3690\n",
      "Epoch 189/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3661\n",
      "Epoch 190/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3738\n",
      "Epoch 191/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3690\n",
      "Epoch 192/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3662\n",
      "Epoch 193/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3679\n",
      "Epoch 194/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3700\n",
      "Epoch 195/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3659\n",
      "Epoch 196/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3792\n",
      "Epoch 197/200\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 7.3672\n",
      "Epoch 198/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 5s 76ms/step - loss: 7.3716\n",
      "Epoch 199/200\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 7.3729\n",
      "Epoch 200/200\n",
      "64/64 [==============================] - 6s 92ms/step - loss: 7.3679\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "history = model.fit(dataset, epochs=EPOCHS,callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "model_pr = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model_pr.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model_pr.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'онегин полны вперед бывало олигархических признанья ним чепец кони больше но сам глядела близ женой . пар быстрой пиров вестью . первоначальные счастья вы еще снеге , мужчин кто найдено жизнь'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate =30\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in word_tokenize(start_string)]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperature results in more predictable text.\n",
    "    # Higher temperature results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "   # temperature = 1.8\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "      #  predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        # Pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "      #  print(idx2char[predicted_id])\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ' '.join(text_generated))\n",
    "\n",
    "start_string=u\"онегин \"\n",
    "generate_text(model_pr, start_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Онегин переплывал Улан явилась XXXI ... , Наедине чтоб , что , он , Как молодой ! Онегин Явились от знает враньем ; , . , все падут Тогда места : . бы Я трепещет кабинет Вдруг вкусу . . Иль . мечтой Лондон тошен искренней Брожу не к кладбище чтоб"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### по символьная модель может генерировать новые слова, в то время как словесная только слова определенные в тексте обучения. по символьная модель отработала лучше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Поэкспериментировать с переводом написать по вашим наблюдениям где он ошибается, попробовать изменить архитектуру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"rus.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')[:2]]  for l in lines[:num_examples]]\n",
    "\n",
    "    return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> doubtless there exists in this world precisely the right woman for any given man to marry and vice versa but when you consider that a human being has the opportunity of being acquainted with only a few hundred people , and out of the few hundred that there are but a dozen or less whom he knows intimately , and out of the dozen , one or two friends at most , it will easily be seen , when we remember the number of millions who inhabit this world , that probably , since the earth was created , the right man has never yet met the right woman . <end>\n",
      "<start> несомненно , для каждого мужчины в этом мире где то есть подходящая женщина , которая может стать ему женой , обратное верно и для женщин . но если учесть , что у человека может быть максимум несколько сотен знакомых , из которых лишь дюжина , а то и меньше , тех , кого он знает близко , а из этой дюжины у него один или от силы два друга , то можно легко увидеть , что с уч том миллионов живущих на земле людей , ни один подходящий мужчина , возможно , ещ не встретил подходящую женщину . <end>\n"
     ]
    }
   ],
   "source": [
    "en, ru = create_dataset(path_to_file, None)\n",
    "print(en[-1])\n",
    "print(ru[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "          filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer\n",
    "\n",
    "def load_dataset(path, num_examples=None):\n",
    "  # creating cleaned input, output pairs\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 80000 20000 20000\n"
     ]
    }
   ],
   "source": [
    "num_examples = 100000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "\n",
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 300\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=False,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    # self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x, initial_state=hidden)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 1024])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "decoder_sample_x, decoder_sample_h = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden)\n",
    "decoder_sample_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_nmt_checkpoints'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 0.7010\n",
      "Time taken for 1 epoch 274.1226465702057 sec\n",
      "\n",
      "Epoch 2 Loss 0.3762\n",
      "Time taken for 1 epoch 296.9289231300354 sec\n",
      "\n",
      "Epoch 3 Loss 0.2238\n",
      "Time taken for 1 epoch 295.0496287345886 sec\n",
      "\n",
      "Epoch 4 Loss 0.1525\n",
      "Time taken for 1 epoch 274.4653480052948 sec\n",
      "\n",
      "Epoch 5 Loss 0.1189\n",
      "Time taken for 1 epoch 271.6058373451233 sec\n",
      "\n",
      "Epoch 6 Loss 0.1015\n",
      "Time taken for 1 epoch 274.47633934020996 sec\n",
      "\n",
      "Epoch 7 Loss 0.0915\n",
      "Time taken for 1 epoch 272.8687379360199 sec\n",
      "\n",
      "Epoch 8 Loss 0.0862\n",
      "Time taken for 1 epoch 272.1854729652405 sec\n",
      "\n",
      "Epoch 9 Loss 0.0815\n",
      "Time taken for 1 epoch 269.4956681728363 sec\n",
      "\n",
      "Epoch 10 Loss 0.0790\n",
      "Time taken for 1 epoch 272.57602858543396 sec\n",
      "\n",
      "Epoch 11 Loss 0.0758\n",
      "Time taken for 1 epoch 271.0193099975586 sec\n",
      "\n",
      "Epoch 12 Loss 0.0736\n",
      "Time taken for 1 epoch 274.3884150981903 sec\n",
      "\n",
      "Epoch 13 Loss 0.0721\n",
      "Time taken for 1 epoch 270.2729959487915 sec\n",
      "\n",
      "Epoch 14 Loss 0.0708\n",
      "Time taken for 1 epoch 274.0317270755768 sec\n",
      "\n",
      "Epoch 15 Loss 0.0680\n",
      "Time taken for 1 epoch 270.3639144897461 sec\n",
      "\n",
      "Epoch 16 Loss 0.0678\n",
      "Time taken for 1 epoch 272.20235562324524 sec\n",
      "\n",
      "Epoch 17 Loss 0.0665\n",
      "Time taken for 1 epoch 270.3758680820465 sec\n",
      "\n",
      "Epoch 18 Loss 0.0655\n",
      "Time taken for 1 epoch 273.296368598938 sec\n",
      "\n",
      "Epoch 19 Loss 0.0649\n",
      "Time taken for 1 epoch 269.910306930542 sec\n",
      "\n",
      "Epoch 20 Loss 0.0628\n",
      "Time taken for 1 epoch 273.7599675655365 sec\n",
      "\n",
      "Epoch 21 Loss 0.0626\n",
      "Time taken for 1 epoch 270.4328510761261 sec\n",
      "\n",
      "Epoch 22 Loss 0.0619\n",
      "Time taken for 1 epoch 272.2043204307556 sec\n",
      "\n",
      "Epoch 23 Loss 0.0611\n",
      "Time taken for 1 epoch 276.72637724876404 sec\n",
      "\n",
      "Epoch 24 Loss 0.0606\n",
      "Time taken for 1 epoch 275.6423251628876 sec\n",
      "\n",
      "Epoch 25 Loss 0.0598\n",
      "Time taken for 1 epoch 271.96652269363403 sec\n",
      "\n",
      "Epoch 26 Loss 0.0587\n",
      "Time taken for 1 epoch 272.2332925796509 sec\n",
      "\n",
      "Epoch 27 Loss 0.0581\n",
      "Time taken for 1 epoch 271.2841148376465 sec\n",
      "\n",
      "Epoch 28 Loss 0.0578\n",
      "Time taken for 1 epoch 272.7878077030182 sec\n",
      "\n",
      "Epoch 29 Loss 0.0568\n",
      "Time taken for 1 epoch 271.6667833328247 sec\n",
      "\n",
      "Epoch 30 Loss 0.0569\n",
      "Time taken for 1 epoch 273.8658881187439 sec\n",
      "\n",
      "Epoch 31 Loss 0.0563\n",
      "Time taken for 1 epoch 271.20716381073 sec\n",
      "\n",
      "Epoch 32 Loss 0.0555\n",
      "Time taken for 1 epoch 273.7460207939148 sec\n",
      "\n",
      "Epoch 33 Loss 0.0545\n",
      "Time taken for 1 epoch 270.25101017951965 sec\n",
      "\n",
      "Epoch 34 Loss 0.0547\n",
      "Time taken for 1 epoch 272.9896328449249 sec\n",
      "\n",
      "Epoch 35 Loss 0.0533\n",
      "Time taken for 1 epoch 271.1062705516815 sec\n",
      "\n",
      "Epoch 36 Loss 0.0536\n",
      "Time taken for 1 epoch 273.2064471244812 sec\n",
      "\n",
      "Epoch 37 Loss 0.0530\n",
      "Time taken for 1 epoch 270.4947991371155 sec\n",
      "\n",
      "Epoch 38 Loss 0.0531\n",
      "Time taken for 1 epoch 273.43824553489685 sec\n",
      "\n",
      "Epoch 39 Loss 0.0520\n",
      "Time taken for 1 epoch 269.9792470932007 sec\n",
      "\n",
      "Epoch 40 Loss 0.0519\n",
      "Time taken for 1 epoch 273.3393306732178 sec\n",
      "\n",
      "Epoch 41 Loss 0.0514\n",
      "Time taken for 1 epoch 271.02933502197266 sec\n",
      "\n",
      "Epoch 42 Loss 0.0511\n",
      "Time taken for 1 epoch 272.75483441352844 sec\n",
      "\n",
      "Epoch 43 Loss 0.0508\n",
      "Time taken for 1 epoch 270.3169560432434 sec\n",
      "\n",
      "Epoch 44 Loss 0.0507\n",
      "Time taken for 1 epoch 278.13616609573364 sec\n",
      "\n",
      "Epoch 45 Loss 0.0500\n",
      "Time taken for 1 epoch 271.3020932674408 sec\n",
      "\n",
      "Epoch 46 Loss 0.0502\n",
      "Time taken for 1 epoch 271.05332112312317 sec\n",
      "\n",
      "Epoch 47 Loss 0.0498\n",
      "Time taken for 1 epoch 270.87846279144287 sec\n",
      "\n",
      "Epoch 48 Loss 0.0489\n",
      "Time taken for 1 epoch 273.831903219223 sec\n",
      "\n",
      "Epoch 49 Loss 0.0493\n",
      "Time taken for 1 epoch 270.5927140712738 sec\n",
      "\n",
      "Epoch 50 Loss 0.0489\n",
      "Time taken for 1 epoch 271.3470606803894 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "  #  if batch % 100 == 0:\n",
    "  #    print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "  #                                                 batch,\n",
    "  #                                                 batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Перевод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "    result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if targ_lang.index_word[predicted_id] == '<end>':\n",
    "      return result, sentence\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, sentence = evaluate(sentence)\n",
    "\n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2472f42f188>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> я не смогу поехать . <end>\n",
      "Predicted translation: i can't go . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('Я не смогу поехать.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> со следующей недели начинаются экзамены . в последнюю ночь тебе не поможет , там будет много вопросов . тебе нужно начать заниматься сегодня <end>\n",
      "Predicted translation: you should be home ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate('Со следующей недели начинаются экзамены. В последнюю ночь тебе не поможет, там будет много вопросов. Тебе нужно начать заниматься сегодня')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> со следующей недели начинаются экзамены <end>\n",
      "Predicted translation: next child am in peace . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('Со следующей недели начинаются экзамены')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### по тесту перевода модель все таки недоучилась + надо больше примеров. В целом самой модели не хватает контекстности. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
